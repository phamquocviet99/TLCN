{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport re\nimport keras\nimport random\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom keras.applications import DenseNet121,Xception, DenseNet201\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport h5py\n\nhf = h5py.File('../input/breastnew4k/Train224x224xnew.h5', 'r')\nhf.keys()\n\nx = np.array(hf.get('x'))\ny = np.array(hf.get('y'))\n\n\nlabels = np.load('../input/breastcancer225x500/Cancerlabels.npy')\n\nhf.close()\n\ndel hf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NewVer\nimport numpy as np\nimport h5py\n\nhf_train = h5py.File('../input/1234456/Train1.h5', 'r')\nhf_train.keys()\nhf_test = h5py.File('../input/cogangthemchutnuaaaaa/Valid1.h5', 'r')\nhf_test.keys()\nlabels = np.load('../input/breastcancer225x500/Cancerlabels.npy')\nx_train = np.array(hf_train.get('x'))\ny_train = np.array(hf_train.get('y'))\nx_test = np.array(hf_test.get('x'))\ny_test = np.array(hf_test.get('y'))\nhf_train.close()\nhf_test.close()\n\ndel hf_train, hf_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nlabel_binarizer = LabelBinarizer()\ny_train = label_binarizer.fit_transform(y_train)\ny_test = label_binarizer.fit_transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nlabel_binarizer = LabelBinarizer()\ny = label_binarizer.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x , y , test_size = 0.2 , stratify = y , random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del x,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del  model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    pre_trained_model = DenseNet121(input_shape=(224,224,3),include_top=False, weights=\"imagenet\")\n    \n#     for layer in pre_trained_model.layers[:15]:\n        #layer.trainable = False\n    \n    model = Sequential([\n        pre_trained_model,\n        MaxPool2D((2,2) , strides = 2),\n        Flatten(),\n        Dense(4 , activation='softmax')])\n    model.compile(optimizer = \"adam\" , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(x_train),len(x_test),len(y_test),len(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 3, verbose=1,factor=0.3, min_lr=0.000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(learning_rate_reduction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train,y_train, batch_size = 64 , epochs =64  , validation_data = (x_test, y_test),callbacks = [learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"Densenet201.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history['val_loss']\n\n   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = [i for i in range(64)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\n\ntrain_loss = history.history['loss']\n\nval_acc = history.history['loss']\n\nval_loss = history.history['val_loss']\n\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'ro-' , label = 'Valid Accuracy')\nax[0].set_title('Training & Testing Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'r-o' , label = 'Valid Loss')\nax[1].set_title('Training & Testing Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef plot_model_history(model_history, acc='accuracy', val_acc='val_accuracy'):\n    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n    axs[0].plot(range(1, len(model_history.history[acc][2:63]) + 1), model_history.history[acc][2:63])\n    axs[0].plot(range(1, len(model_history.history[val_acc][2:63]) + 1), model_history.history[val_acc][2:63])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1, len(model_history.history[acc][2:63]) + 1), len(model_history.history[acc][2:63]) / 10)\n    axs[0].legend(['train', 'val'], loc='best')\n    axs[1].plot(range(1, len(model_history.history['loss'][2:63]) + 1), model_history.history['loss'][2:63])\n    axs[1].plot(range(1, len(model_history.history['val_loss'][2:63]) + 1), model_history.history['val_loss'][2:63])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1, len(model_history.history['loss'][2:63]) + 1), len(model_history.history['loss'][2:63]) / 10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()\n    plt.savefig('roc.png')\n \nplot_model_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_classes(x_test)\npredictions[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_inv = label_binarizer.inverse_transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test_inv, predictions, target_names = labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test_inv,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = pd.DataFrame(cm , index = labels , columns = labels)\nplt.figure(figsize = (10,10))\nsns.heatmap(cm,cmap= \"Reds\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = labels , yticklabels = labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('Xeption_new.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = tf.keras.models.load_model('../input/tlcn-model/BreastCancer224.h5')\n\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = [i for i in range(50)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\nax[0].set_title('Training & Testing Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'r-o' , label = 'Testing Loss')\nax[1].set_title('Training & Testing Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_inv = label_binarizer.inverse_transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test_inv, predictions, target_names = labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test_inv,predictions)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = pd.DataFrame(cm , index = labels , columns = labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = labels , yticklabels = labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.experimental.export_saved_model(model, 'model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(path):\n#path ='../input/asdfghjkl/begin.png'\n    img = cv2.imread(path)\n    plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n    #plt.show()\n    \n    img_size=225\n    img = cv2.resize(img,(img_size,img_size),3)\n    img = np.array(img) / 255\n    img = np.array(img)\n    img = img.reshape(-1, img_size, img_size, 3)\n    # Generate predictions for samples\n    predictions = model.predict(img)\n    return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = predict(r'../input/testdata/test37.tif')\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}